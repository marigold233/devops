# fluentd/conf/fluent.conf
#
#
#

##################### syslog #########################
<source>
  @type syslog
  port 5140
  bind 0.0.0.0
  tag system
  <parse>
    message_format rfc5424
  </parse>
</source>


##################### forward #########################
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker
</source>

<source>
  @type tail
  path /logs/var/log/nginx/access.log
  pos_file /fluent-temp/access.log.pos
  tag nginx.access
  read_from_head true
  #refresh_interval 5 # default
  <parse>
    @type nginx
    #time_key time
  </parse>
</source>

<source>
  @type tail
  path /logs/var/log/nginx/error.log
  pos_file /fluent-temp/error.log.pos
  tag nginx.error
  read_from_head true
  <parse>
    @type none
  </parse>
</source>

<filter nginx.* system.**>
  #@type stdout
  @type record_modifier
  <record>
    hostname "#{Socket.gethostname}"
    local_ip  "#{ENV['LOCAL_IP']}"
    tag ${tag}
    service_name ${tag_parts[0]}
  </record>
</filter>

<filter docker.**>
   @type parser
   key_name log
   reserve_data true
   remove_key_name_field true
   <parse>
     @type apache2
   </parse>
</filter>

<filter docker.**>
   @type record_modifier
   enable_ruby
   <record>
     local_ip "#{ENV['LOCAL_IP']}"
     container_name ${record["container_name"].delete('/')}
     #tag 重写，注意后续match匹配
     tag ${tag}.${record["container_name"].delete('/')}
     service_name ${tag_parts[0]}
   </record>
</filter>

<match nginx.* system.** docker.**>
  @type elasticsearch
  host 192.168.56.10
  port 9200
  user logstash_internal
  password 123456
  default_elasticsearch_version 8
  index_name fluentd.${tag}.%Y%m%d
  include_timestamp true
  <buffer tag, time>
    @type file
    # 注意将buf文件挂载到宿主机，防止容器gg
    path /logs/var/fluentd-buf
    flush_mode interval
    flush_interval 15s
    flush_thread_count 5
    timekey 1m # chunks per hours ("3600" also available)
  </buffer>
</match>


#<match docker.**>
#  @type stdout
#</match>
